{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\p\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('metadata/UrbanSound8K.csv')\n",
    "valid_data = data[['slice_file_name', 'fold' ,'classID', 'class']][ data['end']-data['start'] >= 3 ]\n",
    "valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "# D=[]\n",
    "        \n",
    "# for row in tqdm_notebook(valid_data.itertuples()): \n",
    "#     print(row.path)\n",
    "#     print(row.classID)\n",
    "#     y1, sr1 = librosa.load(\"audio/\" + row.path, duration=2.97)  \n",
    "#     ps = librosa.feature.melspectrogram(y=y1, sr=sr1)\n",
    "#     if ps.shape != (128, 128): \n",
    "#             continue\n",
    "#     D.append( (ps, row.classID) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import hickle as hkl \n",
    "# # data = D\n",
    "# # # Dump data to file\n",
    "# # hkl.dump(data, 'new_data_file.hkl')\n",
    "# # Load data from file\n",
    "# D = hkl.load('new_data_file.hkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = D\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train = dataset[:7000]\n",
    "test = dataset[7000:]\n",
    "\n",
    "X_train, y_train = zip(*train)\n",
    "X_test, y_test = zip(*test)\n",
    "\n",
    "X_train = np.array([x.reshape( (128, 128, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (128, 128, 1) ) for x in X_test])\n",
    "\n",
    "\n",
    "y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(128, 128, 1)\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 467 samples\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    epochs=12,\n",
    "    batch_size=128,\n",
    "    validation_data= (X_test, y_test))\n",
    "\n",
    "score = model.evaluate(\n",
    "    x=X_test,\n",
    "    y=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    " \n",
    "# model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
